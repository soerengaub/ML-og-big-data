{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\"\n",
    "\n",
    "# Send a HTTP request to the URL of the webpage you want to access\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a ZipFile object from the response content\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "\n",
    "# Extract the 'day.csv' or 'hour.csv' file from the ZipFile object\n",
    "csv_file = zip_file.open('day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV data\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# Drop the 'dteday' column\n",
    "data = data.drop('dteday', axis=1)\n",
    "\n",
    "# Split the data into predictors and target\n",
    "X = data.drop(['cnt', 'casual', 'registered'], axis=1)\n",
    "y = data['cnt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initial split: 60% training, 40% for combined validation and testing\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "# Number of iterations for random splitting\n",
    "num_iterations = 20\n",
    "\n",
    "# Randomly split the 40% data into validation and testing sets (50% each)\n",
    "# Store the mean squared errors for each iteration\n",
    "mse_scores = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_iterations):\n",
    "    # Randomly split the 40% data into validation and testing sets (50% each)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=i)\n",
    "\n",
    "    # Create and train the model\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_pred_val = regressor.predict(X_val)\n",
    "\n",
    "    # Calculate mean squared error on the validation set\n",
    "    mse = mean_squared_error(y_val, y_pred_val)\n",
    "    mse_scores.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plotting the MSE scores as a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, len(mse_scores)+1), mse_scores, color='blue')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title(f'MSE Scores for Different Validation Splits (Variance: {variance:.2f})')\n",
    "plt.xticks(range(1, len(mse_scores)+1))\n",
    "plt.savefig('pictures/validation_set_variance.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance of MSE scores\n",
    "variance = np.var(mse_scores)\n",
    "\n",
    "print(f'MSE Scores: {mse_scores}')\n",
    "print(f'Variance of MSE Scores: {variance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-One-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "# Initialize LeaveOneOut cross-validator\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Create a LinearRegression object\n",
    "regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store the mean squared errors\n",
    "mse_scores = []\n",
    "\n",
    "# Perform LOOCV\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Calculate mean squared error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average mean squared error\n",
    "average_mse = np.mean(mse_scores)\n",
    "print(f'Average Mean Squared Error: {average_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Initialize KFold cross-validator with 10 splits\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# Create a LinearRegression object\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# To store the mean squared errors\n",
    "mse_scores = []\n",
    "\n",
    "# Perform 10-Fold CV\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Calculate mean squared error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Calculate the average mean squared error\n",
    "average_mse = np.mean(mse_scores)\n",
    "print(f'Average Mean Squared Error: {average_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset\n",
    "data_windspeed = data['windspeed'].values\n",
    "data_windspeed.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_windspeed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Function to perform bootstrapping\n",
    "def bootstrap_confidence_interval(data, n_bootstraps=5000, ci=95):\n",
    "    bootstrap_means = []\n",
    "    \n",
    "    # Generate bootstrap samples and compute their means\n",
    "    for _ in range(n_bootstraps):\n",
    "        bootstrap_sample = resample(data, replace=True)\n",
    "        bootstrap_means.append(np.mean(bootstrap_sample))\n",
    "    \n",
    "    # Compute the percentiles to form the confidence interval\n",
    "    lower_percentile = (100 - ci) / 2\n",
    "    upper_percentile = 100 - lower_percentile\n",
    "    confidence_interval = np.percentile(bootstrap_means, [lower_percentile, upper_percentile])\n",
    "    \n",
    "    return confidence_interval, bootstrap_means\n",
    "\n",
    "\n",
    "confidence_level = 95\n",
    "\n",
    "# Calculate the confidence interval\n",
    "confidence_interval, bootstrap_means = bootstrap_confidence_interval(data_windspeed, ci=confidence_level)\n",
    "\n",
    "print(f\"Estimated {confidence_level}% confidence interval for the mean: {confidence_interval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Histogram of bootstrap means\n",
    "plt.hist(bootstrap_means, bins=30, color='blue', alpha=0.7, label='Bootstrap Means')\n",
    "\n",
    "# Confidence interval\n",
    "plt.axvline(confidence_interval[0], color='red', linestyle='--', label='95% CI Lower Bound')\n",
    "plt.axvline(confidence_interval[1], color='green', linestyle='--', label='95% CI Upper Bound')\n",
    "\n",
    "# Original sample mean\n",
    "plt.axvline(data_windspeed.mean(), color='yellow', linestyle='-', label='Original Sample Mean')\n",
    "\n",
    "plt.title('Bootstrap Means and Confidence Interval for the Mean')\n",
    "plt.xlabel('Mean Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(fontsize=12, loc='upper right', bbox_to_anchor=(1.6, 1))\n",
    "plt.savefig('pictures/bootstrap_mean.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap for Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform bootstrap for model evaluation\n",
    "def bootstrap_model_evaluation(X_train, y_train, model, B=100, test_size=0.2):\n",
    "    mse_scores = []\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_training, X_validation, y_training, y_validation = train_test_split(\n",
    "        X_train, y_train, test_size=test_size\n",
    "    )\n",
    "\n",
    "    for i in range(B):\n",
    "        # Prepare the bootstrap sample\n",
    "        X_sample, y_sample = resample(X_training, y_training)\n",
    "\n",
    "        # Fit the model to the bootstrap sample\n",
    "        model.fit(X_sample, y_sample)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        y_pred = model.predict(X_validation)\n",
    "        mse = mean_squared_error(y_validation, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "    # Calculate bootstrap statistics\n",
    "    mean_mse = np.mean(mse_scores)\n",
    "    mse_ci_lower = np.percentile(mse_scores, 2.5)\n",
    "    mse_ci_upper = np.percentile(mse_scores, 97.5)\n",
    "\n",
    "    return mean_mse, mse_ci_lower, mse_ci_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Instantiate the models\n",
    "linear_model = LinearRegression()\n",
    "decision_tree_model = DecisionTreeRegressor()\n",
    "\n",
    "# Evaluate Linear Regression model using bootstrap\n",
    "lr_mean_mse, lr_mse_ci_lower, lr_mse_ci_upper = bootstrap_model_evaluation(X_train, y_train, linear_model)\n",
    "\n",
    "# Evaluate Decision Tree model using bootstrap\n",
    "dt_mean_mse, dt_mse_ci_lower, dt_mse_ci_upper = bootstrap_model_evaluation(X_train, y_train, decision_tree_model)\n",
    "\n",
    "# Print results for Linear Regression\n",
    "print(f\"Linear Regression - Bootstrap Mean MSE: {lr_mean_mse:.2f}\")\n",
    "print(f\"Linear Regression - 95% Confidence interval for the MSE: [{lr_mse_ci_lower:.2f}, {lr_mse_ci_upper:.2f}]\")\n",
    "\n",
    "# Print results for Decision Tree\n",
    "print(f\"Decision Tree - Bootstrap Mean MSE: {dt_mean_mse:.2f}\")\n",
    "print(f\"Decision Tree - 95% Confidence interval for the MSE: [{dt_mse_ci_lower:.2f}, {dt_mse_ci_upper:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
