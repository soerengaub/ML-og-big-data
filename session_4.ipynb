{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "# URL for the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases\\\n",
    "/00275/Bike-Sharing-Dataset.zip\"\n",
    "# Send a HTTP request to the URL of the webpage you want to access\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a ZipFile object from the response content\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "# Extract the 'day.csv' or 'hour.csv' file from the ZipFile object\n",
    "csv_file = zip_file.open('day.csv')\n",
    "# Read the CSV data\n",
    "data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    def __init__(self):\n",
    "        self.beta = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Add a column of ones to X for the intercept term\n",
    "        X = np.hstack([np.ones([X.shape[0], 1]), X])\n",
    "        \n",
    "        # Calculate the parameters beta\n",
    "        self.beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Add a column of ones to X for the intercept term\n",
    "        X = np.hstack([np.ones([X.shape[0], 1]), X])\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = X @ self.beta\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearClassification(MyLinearRegression):\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Add a column of ones to X for the intercept term\n",
    "        X = np.hstack([np.ones([X.shape[0], 1]), X])\n",
    "\n",
    "        # Make predictions\n",
    "\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        # Use predict_proba to predict the label 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select two features related to weather and season\n",
    "features = ['temp', 'windspeed']\n",
    "\n",
    "target = 'cnt_more_than_4000'\n",
    "\n",
    "# Define the target variable\n",
    "data[target] = (data['cnt'] > 4000).astype(int)\n",
    "\n",
    "# Define the feature matrix X and the target variable y\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "linear_classifier = MyLinearClassification()\n",
    "linear_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class labels on the test set\n",
    "y_pred = linear_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def draw_decision_boundary(\n",
    "    X, y, model, file_name, \n",
    "    title=\"2-Class classification (temperature vs windspeed)\", \n",
    "    x_label='temp',\n",
    "    y_label='windspeed'):\n",
    "    # Create color maps\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])\n",
    "    cmap_bold = ListedColormap(['#FF0000', '#00FF00'])\n",
    "\n",
    "    # Step size in the mesh\n",
    "    h = .02\n",
    "\n",
    "    # Calculate the min, max and limits\n",
    "    x_min, x_max = X.values[:, 0].min() - 0.1, X.values[:, 0].max() + 0.1\n",
    "    y_min, y_max = X.values[:, 1].min() - 0.1, X.values[:, 1].max() + 0.1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Predict the class for each mesh point\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Create a mask for the two classes\n",
    "    mask = y.values == 1\n",
    "\n",
    "    # Plot the points for class 0\n",
    "    plt.scatter(X.values[~mask, 0], X.values[~mask, 1], c=cmap_bold.colors[0], edgecolor='k', s=20, label='False')\n",
    "\n",
    "    # Plot the points for class 1\n",
    "    plt.scatter(X.values[mask, 0], X.values[mask, 1], c=cmap_bold.colors[1], edgecolor='k', s=20, label='True')\n",
    "\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "\n",
    "    # Add a legend\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(file_name)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_decision_boundary(X=X, y=y, model=linear_classifier, file_name='pictures/lr_boundary.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def domain_comparasion():\n",
    "    # Create the figure and axes objects\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Generate some synthetic data\n",
    "    np.random.seed(0)\n",
    "    X = np.random.randn(100, 1)\n",
    "    y = (X[:, 0] > 0).astype(float)\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    lin_reg = LinearRegression().fit(X, y)\n",
    "\n",
    "    # Fit a logistic regression model\n",
    "    log_reg = LogisticRegression().fit(X, y)\n",
    "\n",
    "    # Generate some points to predict\n",
    "    X_test = np.linspace(-3, 3, 1000).reshape(-1, 1)\n",
    "\n",
    "    # Predict with both models\n",
    "    y_pred_lin = lin_reg.predict(X_test)\n",
    "    y_pred_log = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Plot the actual data points\n",
    "    sns.scatterplot(x=X[:, 0], y=y, ax=ax, color='blue', alpha=0.5, label='Data')\n",
    "\n",
    "    # Plot the predictions of the linear regression model\n",
    "    sns.lineplot(x=X_test[:, 0], y=y_pred_lin, ax=ax, color='red', alpha=0.8, label='Linear regression')\n",
    "\n",
    "    # Plot the predictions of the logistic regression model\n",
    "    sns.lineplot(x=X_test[:, 0], y=y_pred_log, ax=ax, color='green', alpha=0.8, label='Logistic regression')\n",
    "\n",
    "    # Set the labels of the plot\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('y')\n",
    "\n",
    "    # Show the legend\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig('pictures/logistic_vs_lr.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_comparasion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the logit transformation function\n",
    "def logit(p):\n",
    "    return np.log(p / (1 - p))\n",
    "\n",
    "# Generate a sequence of probabilities between 0 and 1\n",
    "p = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "# Compute the logit transformation for each probability\n",
    "l_p = logit(p)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(p, l_p, label=r'$l(p) = \\log\\left(\\frac{p}{1-p}\\right)$')\n",
    "plt.xlabel('Probability (p)')\n",
    "plt.ylabel('Logit transformation (l(p))')\n",
    "plt.title('Logit Transformation Function')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig('pictures/logit_func.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.beta = None\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Add a column of ones for the bias term\n",
    "        X = np.hstack([np.ones([X.shape[0], 1]), X])\n",
    "        \n",
    "        num_samples, num_features = X.shape\n",
    "\n",
    "        # Initialize beta\n",
    "        self.beta = np.ones(num_features)\n",
    "\n",
    "        # Gradient descent\n",
    "        for _ in range(self.num_iterations):\n",
    "            # Compute prediction probability\n",
    "            p = \n",
    "            # Compute gradients\n",
    "            dw = \n",
    "            # Update beta\n",
    "            self.beta = \n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Add a column of ones for the bias term\n",
    "        X = np.hstack([np.ones([X.shape[0], 1]), X])\n",
    "        \n",
    "        return ?\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "logistic_classifier = MyLogisticRegression()\n",
    "logistic_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class labels on the test set\n",
    "y_pred = logistic_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing actual result to the predicted result\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_decision_boundary(X=X, y=y, model=logistic_classifier, file_name='pictures/logistic_boundary.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Define the grid over the feature space\n",
    "x_min, x_max = X['temp'].min() - .5, X['temp'].max() + .5\n",
    "y_min, y_max = X['windspeed'].min() - .5, X['windspeed'].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "# Predict probabilities on the grid\n",
    "Z_linear = linear_classifier.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z_logistic = logistic_classifier.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Reshape the predicted probabilities for plotting\n",
    "Z_linear = Z_linear.reshape(xx.shape)\n",
    "Z_logistic = Z_logistic.reshape(xx.shape)\n",
    "\n",
    "# Define the colormap for the plot\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])\n",
    "\n",
    "# Plot the predicted probabilities\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(xx, yy, Z_linear, cmap=cmap_light)\n",
    "plt.scatter(X['temp'], X['windspeed'], c=y, edgecolor='k', s=20)\n",
    "plt.title('Linear Regression')\n",
    "plt.xlabel('temp')\n",
    "plt.ylabel('windspeed')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(xx, yy, Z_logistic, cmap=cmap_light)\n",
    "plt.scatter(X['temp'], X['windspeed'], c=y, edgecolor='k', s=20)\n",
    "plt.title('Logistic Regression')\n",
    "plt.xlabel('temp')\n",
    "plt.ylabel('windspeed')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pictures/linear_vs_logistics_boundaries.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a single feature for simplicity\n",
    "def plot_probabilities(linear_classifier, logistic_classifier, X, feature):\n",
    "    X_single = X[[feature]]\n",
    "\n",
    "    # Fit both models\n",
    "    linear_classifier.fit(X_single, y)\n",
    "    logistic_classifier.fit(X_single, y)\n",
    "\n",
    "    # Generate a range of input values\n",
    "    X_test = np.linspace(X_single.min(), X_single.max(), 1000)\n",
    "\n",
    "    # Predict probabilities for each model\n",
    "    proba_linear = linear_classifier.predict_proba(X_test)\n",
    "    proba_logistic = logistic_classifier.predict_proba(X_test)\n",
    "\n",
    "    # Create a plot\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.plot(X_test, proba_linear, label='Linear Regression')\n",
    "    plt.plot(X_test, proba_logistic, label='Logistic Regression')\n",
    "    plt.scatter(X_single, y, edgecolor='k', alpha=0.1)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Predicted Probability')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('pictures/linear_vs_logistic_probabilities.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_probabilities(\n",
    "    linear_classifier=linear_classifier, \n",
    "    logistic_classifier=logistic_classifier, \n",
    "    X=X, feature='temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XOR problem\n",
    "X = np.array([[0, 0],[0, 1],[1, 0],[1, 1]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "\n",
    "# Fit a logistic regression model\n",
    "model = MyLogisticRegression()\n",
    "# model.beta = np.ones(X.shape[1]) \n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict the output for the inputs\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Display the predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_decision_boundary(\n",
    "    X=pd.DataFrame(X), y=pd.DataFrame(y)[0], model=model, \n",
    "    file_name='XOR_boundary.pdf',\n",
    "    title='XOR classifcation',\n",
    "    x_label='x_1',\n",
    "    y_label='x_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "class MyPerceptron:\n",
    "    def __init__(self, learning_rate=10, num_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.model = Sequential([\n",
    "            # You code here\n",
    "            # Use only Dense(units=, input_dim=, activation='sigmoid')\n",
    "\n",
    "        ])\n",
    "        self.model.compile(\n",
    "            loss='mean_squared_error', \n",
    "            optimizer=SGD(learning_rate=self.learning_rate))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, epochs=self.num_iterations)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.model.predict(X)\n",
    "        return y_pred > 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XOR problem\n",
    "X = np.array([[0, 0],[0, 1],[1, 0],[1, 1]])\n",
    "y = np.array([0, 1, 1, 0]).reshape(-1,1)\n",
    "\n",
    "# Fit a logistic regression model\n",
    "model = MyPerceptron()\n",
    "# model.beta = np.ones(X.shape[1]) \n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict the output for the inputs\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Display the predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_decision_boundary(X=pd.DataFrame(X), y=pd.DataFrame(y)[0], model=model, \n",
    "    file_name='XOR_boundary_nn.pdf',\n",
    "    title='XOR classifcation',\n",
    "    x_label='x_1',\n",
    "    y_label='x_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression,\\\n",
    "    Perceptron, SGDClassifier, PassiveAggressiveClassifier\n",
    "\n",
    "y_pred_list = []\n",
    "for model in [LinearRegression(), LogisticRegression(), Perceptron(),\\\n",
    "              SGDClassifier(), PassiveAggressiveClassifier()]:\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred_list.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "y_pred_list = []\n",
    "for model in [DecisionTreeClassifier(), RandomForestClassifier(), SVC(),\\\n",
    "              KNeighborsClassifier(), GradientBoostingClassifier()]:\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred_list.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "y_pred_list = []\n",
    "for model in [GaussianProcessRegressor(), MLPRegressor(), SVR(),\\\n",
    "              RandomForestRegressor(), GradientBoostingRegressor()]:\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred_list.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
