{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# generate data\n",
    "np.random.seed(0)\n",
    "mean = [0, 0]\n",
    "cov = [[1, 0.5], [0.5, 1]]\n",
    "x, y = np.random.multivariate_normal(mean, cov, size=300).T\n",
    "\n",
    "# create a grid for contour plot\n",
    "X, Y = np.mgrid[-3:3:.01, -3:3:.01]\n",
    "pos = np.dstack((X, Y))\n",
    "rv = multivariate_normal(mean, cov)\n",
    "\n",
    "# create seaborn jointplot\n",
    "g = sns.jointplot(x=x, y=y, space=0, alpha=0.8)\n",
    "\n",
    "# plot contour\n",
    "g.ax_joint.contour(X, Y, rv.pdf(pos), colors='r')\n",
    "\n",
    "# set title\n",
    "# plt.suptitle('2D Visualization', fontsize=15)\n",
    "\n",
    "plt.savefig('pictures/joint_dist_2D_vis.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.dstack((X, Y))\n",
    "rv = multivariate_normal(mean, cov)\n",
    "Z = rv.pdf(pos)\n",
    "\n",
    "# create 3D plot\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.plot_surface(X, Y, Z, cmap='viridis', linewidth=0)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "ax.set_title('3D Visualization')\n",
    "\n",
    "plt.savefig('pictures/joint_dist_3D_vis.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Generate sample data with 3 clusters\n",
    "X, y_true = make_blobs(n_samples=300, centers=3, cluster_std=0.60, random_state=0)\n",
    "\n",
    "# Apply kmeans to the data\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "# Plot the data points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=30, cmap='viridis')\n",
    "\n",
    "# Plot the centroids of the clusters\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, alpha=0.5);\n",
    "\n",
    "plt.title(\"Cluster Analysis Illustration\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "\n",
    "plt.savefig('cluster_anlaysis_illustration.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class MyKMeans:\n",
    "    def __init__(self, n_clusters=3, random_state=None, max_iter=300):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.random_state = random_state\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Set the random seed for reproducibility\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "        # Initialize the cluster centers randomly from the data points\n",
    "        rand_indices = \n",
    "        self.cluster_centers_ = \n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            # Step 1: Assign each data point to the nearest center\n",
    "            self.labels_ = \n",
    "\n",
    "            # Step 2: Compute new center as the mean of the data points assigned to each cluster\n",
    "            new_centers = \n",
    "\n",
    "            # Step 3: If the centers do not change, then the algorithm has converged\n",
    "            if np.all(self.cluster_centers_ == new_centers):\n",
    "                break\n",
    "\n",
    "            # Update the centers\n",
    "            self.cluster_centers_ = new_centers\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create some artificial data\n",
    "# np.random.seed(0)\n",
    "C1 = np.random.normal(0, 1, (30, 2))\n",
    "C2 = np.random.normal(3, 1, (30, 2))\n",
    "C3 = np.random.normal(6, 1, (30, 2))\n",
    "data = np.concatenate((C1, C2, C3), axis=0)\n",
    "\n",
    "# Create a figure with 2x2 subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(7, 7))\n",
    "\n",
    "iterations = [1, 2, 3, 20]  # Iterations we want to plot\n",
    "\n",
    "# Initialize the KMeans object\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in range(20):  # Run 20 iterations\n",
    "    # Perform given number of steps of KMeans\n",
    "    kmeans = MyKMeans(n_clusters=3, random_state=1, max_iter=i+1)\n",
    "    kmeans.fit(data)\n",
    "\n",
    "    # If this is an iteration we want to plot, create the plot\n",
    "    if i+1 in iterations:\n",
    "        ax = axs[count//(len(iterations)//2)][count%(len(iterations)//2)]\n",
    "        scatter = ax.scatter(data[:, 0], data[:, 1], c=kmeans.labels_, cmap='viridis', alpha=0.6)\n",
    "        centers_scatter = ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c=['purple', 'green', 'yellow'], s=200, edgecolors='black')\n",
    "        ax.set_title(f'Iteration {i+1}')\n",
    "        count += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pictures/K-means_alg_illustration.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Define the Gaussian distributions corresponding to the cluster centers\n",
    "gaussians = [multivariate_normal(mean=center, cov=np.eye(2)) for center in kmeans.cluster_centers_]\n",
    "\n",
    "# Create a grid for plotting the Gaussian distributions\n",
    "x = np.linspace(-3, 9, 500)\n",
    "y = np.linspace(-3, 9, 500)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "pos = np.dstack((X, Y))\n",
    "\n",
    "# Compute the density of each Gaussian distribution at each point in the grid\n",
    "Zs = [gaussian.pdf(pos) for gaussian in gaussians]\n",
    "\n",
    "# Combine the densities to get the overall density\n",
    "Z = np.sum(Zs, axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "# Plot the overall density\n",
    "contourf = ax.contourf(X, Y, Z, levels=20, cmap='inferno', alpha=0.6)\n",
    "\n",
    "# Plot the data points colored by their cluster assignments\n",
    "scatter = ax.scatter(data[:, 0], data[:, 1], c=kmeans.labels_, cmap='viridis', alpha=0.6)\n",
    "\n",
    "# Plot the cluster centers\n",
    "centers_scatter = ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c=['purple', 'green', 'yellow'], s=200, edgecolors='black')\n",
    "\n",
    "ax.set_title('KMeans Clusters and Corresponding Gaussian Distributions')\n",
    "ax.set_xlabel('Feature 1')\n",
    "ax.set_ylabel('Feature 2')\n",
    "\n",
    "# Add a colorbar\n",
    "fig.colorbar(contourf, ax=ax, label='Probability Density')\n",
    "\n",
    "plt.savefig('pictures/KMeans_gaussian.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class MySpectralClustering:\n",
    "    def __init__(self, n_clusters=2, gamma=1.0):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.gamma = gamma\n",
    "        self.eigenvalues_ = None\n",
    "        self.eigenvectors_ = None\n",
    "\n",
    "    def laplacian(self, W):\n",
    "        # Degree matrix\n",
    "        G = \n",
    "\n",
    "        # Laplacian matrix\n",
    "        L = \n",
    "\n",
    "        return L\n",
    "\n",
    "    def fit_predict(self, X):\n",
    "        # Step 1: Create the similarity graph\n",
    "        # Use gamma as the coefficient for the RBF kernel\n",
    "        W = \n",
    "        np.fill_diagonal(W, 0)\n",
    "\n",
    "        # Step 2: Form the graph Laplacian\n",
    "        L = self.laplacian(W)\n",
    "\n",
    "        # Step 3: Compute the first k eigenvectors\n",
    "        self.eigenvalues_, self.eigenvectors_ = \n",
    "        Z = \n",
    "\n",
    "        # Step 4: Cluster the rows of the matrix of eigenvectors\n",
    "        kmeans = KMeans(self.n_clusters, max_iter=100)\n",
    "        kmeans.fit(?)\n",
    "\n",
    "        return kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# Generate circular data\n",
    "X, y = make_circles(n_samples=300, factor=.5, noise=.05)\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = MyKMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(X)\n",
    "labels_kmeans = kmeans.predict(X)\n",
    "\n",
    "# Perform SpectralClustering\n",
    "spectral = MySpectralClustering(n_clusters=2, gamma=35.0)\n",
    "labels_spectral = spectral.fit_predict(X)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Plot the actual data distribution\n",
    "axs[0].scatter(X[:, 0], X[:, 1], c='black', cmap='viridis', alpha=0.7)\n",
    "axs[0].set_title('Actual Data Distribution')\n",
    "axs[0].set_xlabel('Feature 1')\n",
    "axs[0].set_ylabel('Feature 2')\n",
    "\n",
    "# Plot the KMeans clustering results\n",
    "axs[1].scatter(X[:, 0], X[:, 1], c=labels_kmeans, cmap='viridis', alpha=0.7)\n",
    "axs[1].set_title('KMeans Clustering')\n",
    "axs[1].set_xlabel('Feature 1')\n",
    "axs[1].set_ylabel('Feature 2')\n",
    "\n",
    "# Plot the SpectralClustering results\n",
    "axs[2].scatter(X[:, 0], X[:, 1], c=labels_spectral, cmap='viridis', alpha=0.7)\n",
    "axs[2].set_title('Spectral Clustering')\n",
    "axs[2].set_xlabel('Feature 1')\n",
    "axs[2].set_ylabel('Feature 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pictures/Spectral_Clustering_and_Kmeans.pdf')\n",
    "# plt.savefig('pictures/Kmeans-limitation.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the function for calculating similarity\n",
    "def similarity(d, c):\n",
    "    return np.exp(-d**2 * c)\n",
    "\n",
    "# Create an array of distances\n",
    "distances = np.linspace(0, 5, 400)\n",
    "\n",
    "# Calculate similarities for different scale parameters\n",
    "c_values = [0.2, 1.0, 5.0]\n",
    "for c in c_values:\n",
    "    similarities = similarity(distances, c)\n",
    "    plt.plot(distances, similarities, label=f'$\\gamma$ = {c}')\n",
    "\n",
    "# Decorate the plot\n",
    "plt.xlabel('Distance (d)')\n",
    "plt.ylabel('Similarity Score (s)')\n",
    "plt.title('Similarity vs Distance for different scale parameters ($\\gamma$)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig('pictures/rbf_func.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a weighted graph\n",
    "G = nx.Graph()\n",
    "G.add_edge('A', 'B', weight=0.6)\n",
    "G.add_edge('A', 'C', weight=0.2)\n",
    "G.add_edge('C', 'D', weight=0.1)\n",
    "G.add_edge('C', 'E', weight=0.7)\n",
    "G.add_edge('C', 'F', weight=0.9)\n",
    "G.add_edge('A', 'D', weight=0.3)\n",
    "\n",
    "# Get the node names in the order NetworkX uses internally\n",
    "node_names = list(G.nodes)\n",
    "\n",
    "pos = nx.spring_layout(G)  # positions for all nodes\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.subplot(221)\n",
    "\n",
    "# Draw the graph nodes\n",
    "nx.draw_networkx_nodes(G, pos)\n",
    "\n",
    "# Draw the graph edges\n",
    "nx.draw_networkx_edges(G, pos)\n",
    "\n",
    "# Draw the labels for nodes\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "# Draw the edge weights\n",
    "labels = nx.get_edge_attributes(G,'weight')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "\n",
    "plt.title('Graph')\n",
    "\n",
    "# Draw the weight matrix\n",
    "plt.subplot(222)\n",
    "plt.imshow(nx.adjacency_matrix(G).toarray(), cmap='viridis')\n",
    "plt.xticks(np.arange(len(node_names)), labels=node_names)\n",
    "plt.yticks(np.arange(len(node_names)), labels=node_names)\n",
    "plt.title('Weight Matrix (W)')\n",
    "plt.colorbar()\n",
    "\n",
    "# Draw the degree matrix\n",
    "plt.subplot(223)\n",
    "plt.imshow(np.diag([d for n, d in G.degree(weight='weight')]), cmap='viridis')\n",
    "plt.xticks(np.arange(len(node_names)), labels=node_names)\n",
    "plt.yticks(np.arange(len(node_names)), labels=node_names)\n",
    "plt.title('Degree Matrix (G)')\n",
    "plt.colorbar()\n",
    "\n",
    "# Draw the Laplacian\n",
    "plt.subplot(224)\n",
    "plt.imshow(nx.laplacian_matrix(G).toarray(), cmap='viridis')\n",
    "plt.xticks(np.arange(len(node_names)), labels=node_names)\n",
    "plt.yticks(np.arange(len(node_names)), labels=node_names)\n",
    "plt.title('Laplacian Matrix (L)')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pictures/laplacian_matrix.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigenvectors_explained():\n",
    "    # Create some data\n",
    "    np.random.seed(0)\n",
    "    X = np.dot(np.random.random(size=(2, 2)), np.random.normal(size=(2, 200))).T\n",
    "\n",
    "    # Subtract the mean to center the data at the origin\n",
    "    X = X - np.mean(X, 0)\n",
    "\n",
    "    # Compute the covariance matrix\n",
    "    C = np.cov(X.T)\n",
    "\n",
    "    # Compute the eigenvalues and eigenvectors of the covariance matrix\n",
    "    eigvals, eigvecs = np.linalg.eig(C)\n",
    "\n",
    "    # Transform the data\n",
    "    X_transformed = X @ eigvecs\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "    # Plot the original data\n",
    "    ax[0].scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
    "    for e, v in zip(eigvals, eigvecs.T):\n",
    "        ax[0].plot([0, 3.*np.sqrt(e)*v[0]], [0, 3.*np.sqrt(e)*v[1]], 'r-', lw=2)\n",
    "    ax[0].set_title('Original Data')\n",
    "    ax[0].set_xlabel('x[0]')\n",
    "    ax[0].set_ylabel('x[1]')\n",
    "    ax[0].set_xlim(-2.5,2.5)\n",
    "    ax[0].set_ylim(-2.5,2.5)\n",
    "\n",
    "    # Plot the transformed data\n",
    "    ax[1].scatter(X_transformed[:, 0], X_transformed[:, 1], alpha=0.2)\n",
    "    for e, v in zip(eigvals, np.identity(2)):\n",
    "        ax[1].plot([0, 3.*np.sqrt(e)*v[0]], [0, 3.*np.sqrt(e)*v[1]], 'r-', lw=2)\n",
    "    ax[1].set_title('Transformed Data')\n",
    "    ax[1].set_xlabel('Principal Component 1')\n",
    "    ax[1].set_ylabel('Principal Component 2')\n",
    "    ax[1].set_xlim(-2.5,2.5)\n",
    "    ax[1].set_ylim(-2.5,2.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pictures/eigenvector_data_transform.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvectors_explained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse import csgraph\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# Generate circular data\n",
    "X, y = make_circles(n_samples=300, factor=.5, noise=.05)\n",
    "\n",
    "# Initialize the figure\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "# Plot the data scatter\n",
    "axs[0].scatter(X[:, 0], X[:, 1], c='black', cmap='viridis', alpha=0.7)\n",
    "axs[0].set_title('Data Scatter')\n",
    "axs[0].set_xlabel('Feature 1')\n",
    "axs[0].set_ylabel('Feature 2')\n",
    "\n",
    "# Perform SpectralClustering with various gamma values\n",
    "gamma_values = np.linspace(1, 50, 50)\n",
    "eigenvalues = []\n",
    "for gamma in gamma_values:\n",
    "    spectral = MySpectralClustering(n_clusters=2, gamma=gamma)\n",
    "    spectral.fit_predict(X)\n",
    "    eigenvalues.append(spectral.eigenvalues_[1])  # store the second smallest eigenvalue\n",
    "\n",
    "\n",
    "# Plot the second smallest eigenvector vs the third smallest eigenvector\n",
    "axs[1].scatter(spectral.eigenvectors_[:, 1], spectral.eigenvectors_[:, 2], alpha=0.7)\n",
    "axs[1].set_title('2nd vs 3rd Smallest Eigenvector')\n",
    "axs[1].set_xlabel('2nd Smallest Eigenvector')\n",
    "axs[1].set_ylabel('3rd Smallest Eigenvector')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pictures/spectral_clustering_illustration.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
